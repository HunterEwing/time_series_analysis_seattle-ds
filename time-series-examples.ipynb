{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The study of time series has arisen because certain sorts of data streams are heavily dependent on the flow of time. Of course, we have not totally ignored time as a feature up to this point. The selling price of a house probably *does* have some relation to the season or the year as real estate markets grow and decline with certain temporally-indexed economic changes etc. But surely time is not the most important predictor of house price. Square footage would likely be more strongly correlated with price than would date of sale.\n",
    "\n",
    "But there are other sorts of data that more readily lend themselves to a temporal analysis. One canonical example is numbers from a stock exchange: First, data from stock tickers often arrive as numbers anchored to consecutive units of time. I get the selling price for some stock on January 1, say, and the next bit of information I gain will be the selling price for that stock on January 2. (We'll explore this feature of time series below.) Second, and more important, if I'm interested in actually *predicting* the selling price of a stock for, say, tomorrow, then very likely one piece of very salient (i.e. *correlated*) information would be the selling price of that stock *today*.\n",
    "\n",
    "What other examples of this sort of time-dependent data can you think of?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load some packages.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/google-trends_game-of-thrones_us.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will help us load and\n",
    "# clean up a dataset.\n",
    "\n",
    "def load_trend(trend_name='football', country_code='us'):\n",
    "    df = pd.read_csv('data/google-trends_'\n",
    "                     + trend_name + '_'\n",
    "                     + country_code\n",
    "                     + '.csv').iloc[1:, :]\n",
    "    df.columns = ['counts']\n",
    "    df['counts'] = df['counts'].str.replace('<1', '0').astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_trend(**{'trend_name': 'data-science', 'country_code': 'us'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `**` syntax is used to pass keywords and values in dictionary form to a function. For more on `*` and `**` (`*args` and `**kwargs`), see [this page](https://www.geeksforgeeks.org/args-kwargs-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = [\n",
    "    {'trend_name': 'data-science', 'country_code': 'us'},\n",
    "    {'trend_name': 'football', 'country_code': 'us'},\n",
    "    {'trend_name': 'football', 'country_code': 'uk'},\n",
    "    {'trend_name': 'game-of-thrones', 'country_code': 'us'},\n",
    "    {'trend_name': 'pokemon', 'country_code': 'us'},\n",
    "    {'trend_name': 'taxes', 'country_code': 'us'},   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_dfs = [load_trend(**trend) for trend in trends]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trend_df = trend_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if we can guess which is which just by looking\n",
    "# at their graphs.\n",
    "\n",
    "import matplotlib; matplotlib.style.use('ggplot')\n",
    "\n",
    "fig, axs = plt.subplots(len(trend_dfs), 1, figsize=(8, 10))\n",
    "plt.tight_layout()\n",
    "for i, trend_df in enumerate(trend_dfs):\n",
    "    ax = axs[i]\n",
    "    #ax.set_title(str(trends[i]))\n",
    "    ax.plot(np.array(trend_df.index), trend_df['counts'])\n",
    "    ticks = ax.get_xticks()\n",
    "    ax.set_ylim((0, 100))\n",
    "    ax.set_xticks([tick for tick in ticks if tick%24 == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do a histogram of our data, say of the taxes counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxes_df = load_trend('taxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(taxes_df['counts']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But clearly we would be missing something important about how the data is structured. Let's try to capture that. We'll stick with the taxes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a month column\n",
    "\n",
    "taxes_df['i'] = np.arange(len(taxes_df))\n",
    "taxes_df['month'] = taxes_df['i'] % 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using month to predict tax activity\n",
    "\n",
    "trend_model = LinearRegression()\n",
    "trend_model.fit(taxes_df[['i']], taxes_df['counts'])\n",
    "trend_line = trend_model.predict(taxes_df[['i']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_line[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(taxes_df['i'], taxes_df['counts'])\n",
    "plt.plot(taxes_df['i'], trend_line);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this model leaves something to be desired! Let's try again. And this time we'll make explicit use of the time indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_encoder = OneHotEncoder(categories='auto')\n",
    "month_encoder.fit(taxes_df[['month']])\n",
    "month_data = month_encoder.transform(taxes_df[['month']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack((taxes_df[['i']].values, month_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(data, taxes_df['counts'])\n",
    "lr_pred = lr.predict(data)  # Predictive model based on i and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_df = taxes_df\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.set_title('Taxes')\n",
    "ax.plot(trend_df['i'], trend_df['counts'], label='Data',\n",
    "       linewidth=.5, alpha=.8)\n",
    "ax.plot(trend_df['i'], trend_line, label='Trend')\n",
    "ax.plot(trend_df['i'], lr_pred, label='Regression', linestyle=\"dotted\")\n",
    "plt.legend()\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_ylim((0, 100))\n",
    "ax.set_xticks([tick for tick in ticks if tick%24 == 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = trend_df['counts'] - lr_pred\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.set_title(\"Residuals\")\n",
    "ax.plot(trend_df['i'], trend_df['counts'], label='Data',\n",
    "       linewidth=.5, alpha=.8)\n",
    "ax.plot(trend_df['i'], lr_pred, label='Regression', linestyle=\"dotted\")\n",
    "ax.plot(trend_df['i'], residuals,\n",
    "        label='Residuals', linewidth=.5)\n",
    "\n",
    "#ax.plot(trend_df.index, trend_line, label='trend')\n",
    "plt.legend()\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_ylim((-10, 90))\n",
    "ax.set_xticks([tick for tick in ticks if tick%24 == 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposing a Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statsmodels has a great tool for looking at a time series as a sum of parts: a general trend, a seasonality component, and whatever is left over (often called a residual (why?)): its `seasonal_decompose()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxes_df.index = pd.to_datetime(taxes_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(taxes_df['counts'])\n",
    "\n",
    "observed = decomposition.observed\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(411)\n",
    "plt.plot(observed, label='Original', color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend', color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality', color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals', color=\"blue\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise to make sure that the residual really captures *all* remaining information about our times series.\n",
    "\n",
    "For various techincal reasons that won't concern us here, some of the components of the decomposition have NANs at their heads and tails. But we can just use `np.nansum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "myst = 0\n",
    "for i in range(len(taxes_df['counts'])):\n",
    "    myst += np.nansum(taxes_df['counts'][i] - trend[i] - seasonal[i] - residual[i])\n",
    "myst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
